{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Library to support working with data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data Normalization Support Library\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Performance metrics calculation support library\n",
        "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error, mean_absolute_percentage_error, mean_absolute_error, mean_squared_log_error\n",
        "\n",
        "# Graphing support library\n",
        "from matplotlib import ticker\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>46.209999</td>\n",
              "      <td>46.990002</td>\n",
              "      <td>45.855000</td>\n",
              "      <td>46.259998</td>\n",
              "      <td>40.076595</td>\n",
              "      <td>1289100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>46.099998</td>\n",
              "      <td>44.882999</td>\n",
              "      <td>45.049999</td>\n",
              "      <td>39.028339</td>\n",
              "      <td>1158800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>45.950001</td>\n",
              "      <td>47.180000</td>\n",
              "      <td>45.880001</td>\n",
              "      <td>47.130001</td>\n",
              "      <td>40.830315</td>\n",
              "      <td>1538500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-07</td>\n",
              "      <td>47.310001</td>\n",
              "      <td>48.110001</td>\n",
              "      <td>46.840000</td>\n",
              "      <td>47.740002</td>\n",
              "      <td>41.358772</td>\n",
              "      <td>954700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-08</td>\n",
              "      <td>48.709999</td>\n",
              "      <td>49.480000</td>\n",
              "      <td>48.520000</td>\n",
              "      <td>49.209999</td>\n",
              "      <td>42.632286</td>\n",
              "      <td>1921800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1114</th>\n",
              "      <td>2023-06-06</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>57.294998</td>\n",
              "      <td>52.820000</td>\n",
              "      <td>57.220001</td>\n",
              "      <td>57.220001</td>\n",
              "      <td>6397900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>2023-06-07</td>\n",
              "      <td>57.610001</td>\n",
              "      <td>59.750000</td>\n",
              "      <td>57.520000</td>\n",
              "      <td>59.340000</td>\n",
              "      <td>59.340000</td>\n",
              "      <td>2925500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1116</th>\n",
              "      <td>2023-06-08</td>\n",
              "      <td>59.400002</td>\n",
              "      <td>60.080002</td>\n",
              "      <td>57.910000</td>\n",
              "      <td>58.939999</td>\n",
              "      <td>58.939999</td>\n",
              "      <td>2828400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1117</th>\n",
              "      <td>2023-06-09</td>\n",
              "      <td>58.959999</td>\n",
              "      <td>59.349998</td>\n",
              "      <td>58.290001</td>\n",
              "      <td>58.790001</td>\n",
              "      <td>58.790001</td>\n",
              "      <td>1686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1118</th>\n",
              "      <td>2023-06-12</td>\n",
              "      <td>58.279999</td>\n",
              "      <td>59.650002</td>\n",
              "      <td>58.279999</td>\n",
              "      <td>59.610001</td>\n",
              "      <td>59.610001</td>\n",
              "      <td>1563100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1119 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date       Open       High        Low      Close  Adj Close  \\\n",
              "0     2019-01-02  46.209999  46.990002  45.855000  46.259998  40.076595   \n",
              "1     2019-01-03  46.000000  46.099998  44.882999  45.049999  39.028339   \n",
              "2     2019-01-04  45.950001  47.180000  45.880001  47.130001  40.830315   \n",
              "3     2019-01-07  47.310001  48.110001  46.840000  47.740002  41.358772   \n",
              "4     2019-01-08  48.709999  49.480000  48.520000  49.209999  42.632286   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "1114  2023-06-06  53.000000  57.294998  52.820000  57.220001  57.220001   \n",
              "1115  2023-06-07  57.610001  59.750000  57.520000  59.340000  59.340000   \n",
              "1116  2023-06-08  59.400002  60.080002  57.910000  58.939999  58.939999   \n",
              "1117  2023-06-09  58.959999  59.349998  58.290001  58.790001  58.790001   \n",
              "1118  2023-06-12  58.279999  59.650002  58.279999  59.610001  59.610001   \n",
              "\n",
              "       Volume  \n",
              "0     1289100  \n",
              "1     1158800  \n",
              "2     1538500  \n",
              "3      954700  \n",
              "4     1921800  \n",
              "...       ...  \n",
              "1114  6397900  \n",
              "1115  2925500  \n",
              "1116  2828400  \n",
              "1117  1686600  \n",
              "1118  1563100  \n",
              "\n",
              "[1119 rows x 7 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../../../../Dataset/NTR.csv')\n",
        "df\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reset index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Set the 'Date' column as the index value\n",
        "df.set_index('Date', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the Close column as the dependent variable\n",
        "df_Close = df[['Close']]\n",
        "df_Close = df_Close.reset_index(drop=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Min-max normalization\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(np.array(df_Close))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training, validation and test dataset in a ratio of 6:2:2\n",
        "train_size = int(0.7 * len(data_scaled))\n",
        "val_size = int(0.1 * len(data_scaled))\n",
        "test_size = len(data_scaled) - train_size - val_size\n",
        "\n",
        "train_data = data_scaled[: train_size]\n",
        "val_data = data_scaled[train_size : train_size + val_size]\n",
        "test_data = data_scaled[train_size + val_size :]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install library pmdarima\n",
        "!pip install pmdarima"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparing training data\n",
        "x_train = np.arange(train_size).reshape(-1, 1)\n",
        "y_train = train_data.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing stepwise search to minimize aic\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=-4816.692, Time=0.39 sec\n",
            " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=-4824.673, Time=0.13 sec\n",
            " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=-4822.688, Time=0.06 sec\n",
            " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=-4822.689, Time=0.38 sec\n",
            " ARIMA(0,1,0)(0,0,0)[0]             : AIC=-4825.641, Time=0.21 sec\n",
            " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=-4820.681, Time=0.28 sec\n",
            "\n",
            "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
            "Total fit time: 1.475 seconds\n"
          ]
        }
      ],
      "source": [
        "# Find the best ARIMA model using auto_arima\n",
        "from pmdarima.arima import auto_arima\n",
        "model = auto_arima(y_train, trace=True, error_action='ignore', suppress_warnings=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre> ARIMA(0,1,0)(0,0,0)[0]          </pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ARIMA</label><div class=\"sk-toggleable__content\"><pre> ARIMA(0,1,0)(0,0,0)[0]          </pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "ARIMA(order=(0, 1, 0), scoring_args={}, suppress_warnings=True,\n",
              "      with_intercept=False)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the model\n",
        "model.fit(y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validate Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparing validation data\n",
        "x_val = np.array(range(train_size, train_size + val_size)).reshape(-1, 1)\n",
        "y_val = np.array(val_data).reshape(-1)\n",
        "y_pred_val = model.predict(n_periods = len(y_val))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test = np.array(range(test_size, train_size + val_size + test_size)).reshape(-1, 1)\n",
        "y_test = np.array(test_data).reshape(-1)\n",
        "y_pred = model.predict(n_periods=len(y_test))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE on Validate set:  0.18575080636623506\n",
            "RMSE on Validate set:  21.809797479862716\n",
            "MSLE on Validate set:  0.060723295872321205\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the accuracy of validation\n",
        "y_val = scaler.inverse_transform(np.array([y_val]).reshape(-1, 1))\n",
        "y_pred_val = scaler.inverse_transform(np.array([y_pred_val]).reshape(-1, 1))\n",
        "\n",
        "val_mape = mean_absolute_percentage_error(y_val, y_pred_val)\n",
        "val_mse = mean_squared_error(y_val, y_pred_val)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "val_msle = mean_squared_log_error(y_val, y_pred_val)\n",
        "\n",
        "print(f\"MAPE on Validate set: \", val_mape)\n",
        "print(f\"RMSE on Validate set: \", val_rmse)\n",
        "print(f\"MSLE on Validate set: \", val_msle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE on Test dataset:  0.10062933852104891\n",
            "RMSE on Test dataset:  9.919569151916724\n",
            "MSLE on Test dataset:  0.016629354924271925\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the accuracy of test\n",
        "y_test = scaler.inverse_transform(np.array([y_test]).reshape(-1, 1))\n",
        "y_pred = scaler.inverse_transform(np.array([y_pred]).reshape(-1, 1))\n",
        "\n",
        "test_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "test_mse = mean_squared_error(y_test, y_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_msle = mean_squared_log_error(y_test, y_pred)\n",
        "\n",
        "print(f\"MAPE on Test dataset: \", test_mape)\n",
        "print(f\"RMSE on Test dataset: \", test_rmse)\n",
        "print(f\"MSLE on Test dataset: \", test_msle)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicting the next 30 days"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing the prediction data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The process of creating index predict next 30 days\n",
        "last_index =  df_Close.index[-1]\n",
        "\n",
        "# Create an array of 30 consecutive integers starting from last_index\n",
        "x_next_30_days = np.array(range(last_index + 1, last_index + 31)).reshape(-1, 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted closing prices for the next 30 days:\n",
            "[74.300003 74.300003 74.300003 74.300003 74.300003 74.300003 74.300003\n",
            " 74.300003 74.300003 74.300003 74.300003 74.300003 74.300003 74.300003\n",
            " 74.300003 74.300003 74.300003 74.300003 74.300003 74.300003 74.300003\n",
            " 74.300003 74.300003 74.300003 74.300003 74.300003 74.300003 74.300003\n",
            " 74.300003 74.300003]\n"
          ]
        }
      ],
      "source": [
        "# Predict the closing prices for the next 30 days\n",
        "y_next_30_days = model.predict(n_periods=len(x_next_30_days))\n",
        "y_next_30_days = scaler.inverse_transform(np.array([y_next_30_days]).reshape(-1, 1))\n",
        "\n",
        "# Print the predicted closing prices for the next 30 days\n",
        "print('Predicted closing prices for the next 30 days:')\n",
        "print(y_next_30_days.flatten())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing the forecast date index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the last date from the current index\n",
        "last_date = df.index[-1]\n",
        "\n",
        "# Add one day to the last date\n",
        "next_date = last_date + pd.DateOffset(days=1)\n",
        "\n",
        "# Create a list of indices starting from the next date for 30 days\n",
        "index_next_30_days = pd.date_range(start=next_date, periods=30).tolist()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Drawing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mplot(df\u001b[39m.\u001b[39mindex[:train_size], scaler\u001b[39m.\u001b[39minverse_transform(np\u001b[39m.\u001b[39marray([y_train])\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)))\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mplot(df\u001b[39m.\u001b[39mindex[train_size : train_size \u001b[39m+\u001b[39m val_size], y_val)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# Drawing\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "plt.plot(df.index[:train_size], scaler.inverse_transform(np.array([y_train]).reshape(-1, 1)))\n",
        "\n",
        "plt.plot(df.index[train_size : train_size + val_size], y_val)\n",
        "\n",
        "plt.plot(df.index[train_size : train_size + val_size], y_pred_val)\n",
        "\n",
        "plt.plot(df.index[train_size + val_size :], y_test)\n",
        "\n",
        "plt.plot(df.index[train_size + val_size :], y_pred)\n",
        "\n",
        "plt.plot(index_next_30_days, y_next_30_days)\n",
        "\n",
        "plt.legend(['Train', 'Validate', 'PredictValidate', 'Test', 'PredictTest', 'Next30Day'])\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f\"Nutrien Closing Price Data from {df.index[0].strftime('%Y-%m-%d')} to {index_next_30_days[-1].strftime('%Y-%m-%d')}\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Close value\")\n",
        "plt.savefig('../Image/ARIMA_712_NTR.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
